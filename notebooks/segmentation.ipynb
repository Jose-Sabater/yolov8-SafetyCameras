{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "# model = YOLO(\"yolov8n-seg.pt\")  # load an official model\n",
    "model = YOLO(\"yolov8n-seg.pt\")  # medium\n",
    "\n",
    "# Predict with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_label(image, box, label=\"\", color=(128, 128, 128), txt_color=(255, 255, 255)):\n",
    "    lw = max(round(sum(image.shape) / 2 * 0.003), 2)\n",
    "    p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n",
    "    cv2.rectangle(image, p1, p2, color, thickness=lw, lineType=cv2.LINE_AA)\n",
    "    if label:\n",
    "        tf = max(lw - 1, 1)  # font thickness\n",
    "        w, h = cv2.getTextSize(label, 0, fontScale=lw / 3, thickness=tf)[\n",
    "            0\n",
    "        ]  # text width, height\n",
    "        outside = p1[1] - h >= 3\n",
    "        p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
    "        cv2.rectangle(image, p1, p2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            label,\n",
    "            (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n",
    "            0,\n",
    "            lw / 3,\n",
    "            txt_color,\n",
    "            thickness=tf,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bboxes(image, boxes, labels=[], colors=[], score=True, conf=None):\n",
    "    # Define COCO Labels\n",
    "    if labels == []:\n",
    "        labels = {\n",
    "            0: \"__background__\",\n",
    "            1: \"person\",\n",
    "            2: \"bicycle\",\n",
    "            3: \"car\",\n",
    "            4: \"motorcycle\",\n",
    "            5: \"airplane\",\n",
    "            6: \"bus\",\n",
    "            7: \"train\",\n",
    "            8: \"truck\",\n",
    "            9: \"boat\",\n",
    "            10: \"traffic light\",\n",
    "            11: \"fire hydrant\",\n",
    "            12: \"stop sign\",\n",
    "            13: \"parking meter\",\n",
    "            14: \"bench\",\n",
    "            15: \"bird\",\n",
    "            16: \"cat\",\n",
    "            17: \"dog\",\n",
    "            18: \"horse\",\n",
    "            19: \"sheep\",\n",
    "            20: \"cow\",\n",
    "            21: \"elephant\",\n",
    "            22: \"bear\",\n",
    "            23: \"zebra\",\n",
    "            24: \"giraffe\",\n",
    "            25: \"backpack\",\n",
    "            26: \"umbrella\",\n",
    "            27: \"handbag\",\n",
    "            28: \"tie\",\n",
    "            29: \"suitcase\",\n",
    "            30: \"frisbee\",\n",
    "            31: \"skis\",\n",
    "            32: \"snowboard\",\n",
    "            33: \"sports ball\",\n",
    "            34: \"kite\",\n",
    "            35: \"baseball bat\",\n",
    "            36: \"baseball glove\",\n",
    "            37: \"skateboard\",\n",
    "            38: \"surfboard\",\n",
    "            39: \"tennis racket\",\n",
    "            40: \"bottle\",\n",
    "            41: \"wine glass\",\n",
    "            42: \"cup\",\n",
    "            43: \"fork\",\n",
    "            44: \"knife\",\n",
    "            45: \"spoon\",\n",
    "            46: \"bowl\",\n",
    "            47: \"banana\",\n",
    "            48: \"apple\",\n",
    "            49: \"sandwich\",\n",
    "            50: \"orange\",\n",
    "            51: \"broccoli\",\n",
    "            52: \"carrot\",\n",
    "            53: \"hot dog\",\n",
    "            54: \"pizza\",\n",
    "            55: \"donut\",\n",
    "            56: \"cake\",\n",
    "            57: \"chair\",\n",
    "            58: \"couch\",\n",
    "            59: \"potted plant\",\n",
    "            60: \"bed\",\n",
    "            61: \"dining table\",\n",
    "            62: \"toilet\",\n",
    "            63: \"tv\",\n",
    "            64: \"laptop\",\n",
    "            65: \"mouse\",\n",
    "            66: \"remote\",\n",
    "            67: \"keyboard\",\n",
    "            68: \"cell phone\",\n",
    "            69: \"microwave\",\n",
    "            70: \"oven\",\n",
    "            71: \"toaster\",\n",
    "            72: \"sink\",\n",
    "            73: \"refrigerator\",\n",
    "            74: \"book\",\n",
    "            75: \"clock\",\n",
    "            76: \"vase\",\n",
    "            77: \"scissors\",\n",
    "            78: \"teddy bear\",\n",
    "            79: \"hair drier\",\n",
    "            80: \"toothbrush\",\n",
    "        }\n",
    "    # Define colors\n",
    "    if colors == []:\n",
    "        # colors = [(6, 112, 83), (253, 246, 160), (40, 132, 70), (205, 97, 162), (149, 196, 30), (106, 19, 161), (127, 175, 225), (115, 133, 176), (83, 156, 8), (182, 29, 77), (180, 11, 251), (31, 12, 123), (23, 6, 115), (167, 34, 31), (176, 216, 69), (110, 229, 222), (72, 183, 159), (90, 168, 209), (195, 4, 209), (135, 236, 21), (62, 209, 199), (87, 1, 70), (75, 40, 168), (121, 90, 126), (11, 86, 86), (40, 218, 53), (234, 76, 20), (129, 174, 192), (13, 18, 254), (45, 183, 149), (77, 234, 120), (182, 83, 207), (172, 138, 252), (201, 7, 159), (147, 240, 17), (134, 19, 233), (202, 61, 206), (177, 253, 26), (10, 139, 17), (130, 148, 106), (174, 197, 128), (106, 59, 168), (124, 180, 83), (78, 169, 4), (26, 79, 176), (185, 149, 150), (165, 253, 206), (220, 87, 0), (72, 22, 226), (64, 174, 4), (245, 131, 96), (35, 217, 142), (89, 86, 32), (80, 56, 196), (222, 136, 159), (145, 6, 219), (143, 132, 162), (175, 97, 221), (72, 3, 79), (196, 184, 237), (18, 210, 116), (8, 185, 81), (99, 181, 254), (9, 127, 123), (140, 94, 215), (39, 229, 121), (230, 51, 96), (84, 225, 33), (218, 202, 139), (129, 223, 182), (167, 46, 157), (15, 252, 5), (128, 103, 203), (197, 223, 199), (19, 238, 181), (64, 142, 167), (12, 203, 242), (69, 21, 41), (177, 184, 2), (35, 97, 56), (241, 22, 161)]\n",
    "        colors = [\n",
    "            (89, 161, 197),\n",
    "            (67, 161, 255),\n",
    "            (19, 222, 24),\n",
    "            (186, 55, 2),\n",
    "            (167, 146, 11),\n",
    "            (190, 76, 98),\n",
    "            (130, 172, 179),\n",
    "            (115, 209, 128),\n",
    "            (204, 79, 135),\n",
    "            (136, 126, 185),\n",
    "            (209, 213, 45),\n",
    "            (44, 52, 10),\n",
    "            (101, 158, 121),\n",
    "            (179, 124, 12),\n",
    "            (25, 33, 189),\n",
    "            (45, 115, 11),\n",
    "            (73, 197, 184),\n",
    "            (62, 225, 221),\n",
    "            (32, 46, 52),\n",
    "            (20, 165, 16),\n",
    "            (54, 15, 57),\n",
    "            (12, 150, 9),\n",
    "            (10, 46, 99),\n",
    "            (94, 89, 46),\n",
    "            (48, 37, 106),\n",
    "            (42, 10, 96),\n",
    "            (7, 164, 128),\n",
    "            (98, 213, 120),\n",
    "            (40, 5, 219),\n",
    "            (54, 25, 150),\n",
    "            (251, 74, 172),\n",
    "            (0, 236, 196),\n",
    "            (21, 104, 190),\n",
    "            (226, 74, 232),\n",
    "            (120, 67, 25),\n",
    "            (191, 106, 197),\n",
    "            (8, 15, 134),\n",
    "            (21, 2, 1),\n",
    "            (142, 63, 109),\n",
    "            (133, 148, 146),\n",
    "            (187, 77, 253),\n",
    "            (155, 22, 122),\n",
    "            (218, 130, 77),\n",
    "            (164, 102, 79),\n",
    "            (43, 152, 125),\n",
    "            (185, 124, 151),\n",
    "            (95, 159, 238),\n",
    "            (128, 89, 85),\n",
    "            (228, 6, 60),\n",
    "            (6, 41, 210),\n",
    "            (11, 1, 133),\n",
    "            (30, 96, 58),\n",
    "            (230, 136, 109),\n",
    "            (126, 45, 174),\n",
    "            (164, 63, 165),\n",
    "            (32, 111, 29),\n",
    "            (232, 40, 70),\n",
    "            (55, 31, 198),\n",
    "            (148, 211, 129),\n",
    "            (10, 186, 211),\n",
    "            (181, 201, 94),\n",
    "            (55, 35, 92),\n",
    "            (129, 140, 233),\n",
    "            (70, 250, 116),\n",
    "            (61, 209, 152),\n",
    "            (216, 21, 138),\n",
    "            (100, 0, 176),\n",
    "            (3, 42, 70),\n",
    "            (151, 13, 44),\n",
    "            (216, 102, 88),\n",
    "            (125, 216, 93),\n",
    "            (171, 236, 47),\n",
    "            (253, 127, 103),\n",
    "            (205, 137, 244),\n",
    "            (193, 137, 224),\n",
    "            (36, 152, 214),\n",
    "            (17, 50, 238),\n",
    "            (154, 165, 67),\n",
    "            (114, 129, 60),\n",
    "            (119, 24, 48),\n",
    "            (73, 8, 110),\n",
    "        ]\n",
    "\n",
    "    # plot each boxes\n",
    "    for box in boxes:\n",
    "        # add score in label if score=True\n",
    "        if score:\n",
    "            label = (\n",
    "                labels[int(box[-1]) + 1]\n",
    "                + \" \"\n",
    "                + str(round(100 * float(box[-2]), 1))\n",
    "                + \"%\"\n",
    "            )\n",
    "        else:\n",
    "            label = labels[int(box[-1]) + 1]\n",
    "        # filter every box under conf threshold if conf threshold setted\n",
    "        if conf:\n",
    "            if box[-2] > conf:\n",
    "                color = colors[int(box[-1])]\n",
    "                box_label(image, box, label, color)\n",
    "        else:\n",
    "            color = colors[int(box[-1])]\n",
    "            box_label(image, box, label, color)\n",
    "\n",
    "    # show image\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return image\n",
    "\n",
    "    # closing all open window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 tv, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 2 chairs, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 0.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 wine glass, 2 chairs, 1 tv, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 wine glass, 1 chair, 1 tv, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 wine glass, 1 chair, 1 tv, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 22.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 21.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 21.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 21.0ms\n",
      "Speed: 1.0ms pre-process, 21.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 21.0ms\n",
      "Speed: 1.0ms pre-process, 21.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 21.0ms\n",
      "Speed: 1.0ms pre-process, 21.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 23.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 23.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 21.0ms\n",
      "Speed: 1.0ms pre-process, 21.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 22.1ms\n",
      "Speed: 1.0ms pre-process, 22.1ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 27.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 27.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 28.0ms\n",
      "Speed: 1.0ms pre-process, 28.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 29.0ms\n",
      "Speed: 2.0ms pre-process, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 28.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 28.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.1ms\n",
      "Speed: 1.0ms pre-process, 24.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 22.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 23.0ms\n",
      "Speed: 2.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 tvs, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 tvs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 22.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n",
      "Speed: 2.0ms pre-process, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms pre-process, 23.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 22.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 22.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n",
      "Speed: 2.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 23.2ms\n",
      "Speed: 1.0ms pre-process, 23.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 chair, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 wine glass, 1 chair, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 2 tvs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 26.0ms\n",
      "Speed: 2.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.0ms\n",
      "Speed: 2.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 3 chairs, 2 tvs, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 2 tvs, 25.0ms\n",
      "Speed: 2.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 2.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 26.2ms\n",
      "Speed: 1.0ms pre-process, 26.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 3 chairs, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.0ms\n",
      "Speed: 2.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 2 chairs, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 2 tvs, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 27.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 25.3ms\n",
      "Speed: 1.0ms pre-process, 25.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 35.0ms\n",
      "Speed: 2.0ms pre-process, 35.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.5ms\n",
      "Speed: 1.0ms pre-process, 25.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 3 chairs, 2 tvs, 27.0ms\n",
      "Speed: 2.0ms pre-process, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 4 chairs, 1 tv, 26.0ms\n",
      "Speed: 1.4ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 29.0ms\n",
      "Speed: 1.0ms pre-process, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 chair, 2 tvs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 23.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 2 tvs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.9ms\n",
      "Speed: 1.1ms pre-process, 23.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n",
      "Speed: 0.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 25.0ms\n",
      "Speed: 2.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 2 tvs, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 25.0ms\n",
      "Speed: 2.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 2 tvs, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.0ms\n",
      "Speed: 0.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 2 tvs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 2 tvs, 23.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 2 tvs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 3 chairs, 2 tvs, 24.1ms\n",
      "Speed: 2.0ms pre-process, 24.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 4 chairs, 2 tvs, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 2 tvs, 26.3ms\n",
      "Speed: 1.0ms pre-process, 26.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 2 tvs, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([7, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 tvs, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms pre-process, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 tvs, 25.0ms\n",
      "Speed: 0.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 2 tvs, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 tvs, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 28.0ms\n",
      "Speed: 1.0ms pre-process, 28.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 25.0ms\n",
      "Speed: 2.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 3 chairs, 24.0ms\n",
      "Speed: 2.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 2 chairs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 3 chairs, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 3 chairs, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 3 chairs, 27.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 27.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 29.0ms\n",
      "Speed: 1.0ms pre-process, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 chair, 25.0ms\n",
      "Speed: 2.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 29.0ms\n",
      "Speed: 1.0ms pre-process, 29.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 car, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 1 microwave, 29.0ms\n",
      "Speed: 1.0ms pre-process, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.4ms\n",
      "Speed: 1.0ms pre-process, 23.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 25.1ms\n",
      "Speed: 1.0ms pre-process, 25.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 2 chairs, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n",
      "Speed: 2.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 bird, 1 chair, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.3ms\n",
      "Speed: 1.0ms pre-process, 25.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 couch, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 2 chairs, 1 couch, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 25.6ms\n",
      "Speed: 1.0ms pre-process, 25.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 30.0ms\n",
      "Speed: 2.0ms pre-process, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.2ms\n",
      "Speed: 1.0ms pre-process, 25.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.2ms\n",
      "Speed: 1.0ms pre-process, 26.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 2.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 2.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 30.0ms\n",
      "Speed: 1.0ms pre-process, 30.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 bottle, 1 tv, 29.0ms\n",
      "Speed: 1.0ms pre-process, 29.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 2.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 30.0ms\n",
      "Speed: 1.0ms pre-process, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 27.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 27.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.5ms\n",
      "Speed: 1.0ms pre-process, 26.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.2ms\n",
      "Speed: 1.0ms pre-process, 26.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 bottle, 1 tv, 42.0ms\n",
      "Speed: 1.0ms pre-process, 42.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 29.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.3ms\n",
      "Speed: 1.0ms pre-process, 25.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 31.0ms\n",
      "Speed: 2.0ms pre-process, 31.0ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 2 bottles, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 2.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 2 chairs, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 28.0ms\n",
      "Speed: 1.0ms pre-process, 28.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 24.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms pre-process, 24.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 25.0ms\n",
      "Speed: 2.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 28.0ms\n",
      "Speed: 1.0ms pre-process, 28.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 24.4ms\n",
      "Speed: 1.0ms pre-process, 24.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 27.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 28.0ms\n",
      "Speed: 1.0ms pre-process, 28.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 bottle, 1 tv, 28.0ms\n",
      "Speed: 1.0ms pre-process, 28.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bird, 1 tv, 26.1ms\n",
      "Speed: 2.0ms pre-process, 26.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.4ms\n",
      "Speed: 1.0ms pre-process, 26.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 1 tv, 25.1ms\n",
      "Speed: 2.0ms pre-process, 25.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n",
      "Speed: 2.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 bottle, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.1ms\n",
      "Speed: 2.0ms pre-process, 26.1ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 airplane, 1 tv, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 27.1ms\n",
      "Speed: 1.0ms pre-process, 27.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 2 chairs, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 bottles, 1 tv, 26.0ms\n",
      "Speed: 1.9ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 bottles, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 airplane, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 bottle, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 29.7ms\n",
      "Speed: 1.0ms pre-process, 29.7ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 28.0ms\n",
      "Speed: 1.0ms pre-process, 28.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 2 chairs, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 0.9ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.3ms\n",
      "Speed: 1.0ms pre-process, 26.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 32.0ms\n",
      "Speed: 1.0ms pre-process, 32.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 chair, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 bottles, 2 chairs, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.4ms\n",
      "Speed: 1.0ms pre-process, 26.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 30.0ms\n",
      "Speed: 1.0ms pre-process, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 29.0ms\n",
      "Speed: 1.0ms pre-process, 29.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 bottle, 1 tv, 28.0ms\n",
      "Speed: 1.0ms pre-process, 28.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 30.0ms\n",
      "Speed: 1.0ms pre-process, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 tv, 29.0ms\n",
      "Speed: 1.0ms pre-process, 29.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 airplane, 1 tv, 29.0ms\n",
      "Speed: 1.0ms pre-process, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 28.0ms\n",
      "Speed: 1.0ms pre-process, 28.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 airplane, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 airplane, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 27.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 25.0ms\n",
      "Speed: 2.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 airplane, 27.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 26.2ms\n",
      "Speed: 2.0ms pre-process, 26.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 27.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 27.0ms\n",
      "Speed: 1.0ms pre-process, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 26.0ms\n",
      "Speed: 2.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 28.0ms\n",
      "Speed: 1.0ms pre-process, 28.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([1, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 2 chairs, 1 laptop, 1 cell phone, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bench, 1 cup, 1 tv, 26.3ms\n",
      "Speed: 1.0ms pre-process, 26.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 cup, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 1 cell phone, 26.0ms\n",
      "Speed: 0.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.2ms\n",
      "Speed: 1.0ms pre-process, 26.2ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 cup, 1 chair, 1 tv, 25.0ms\n",
      "Speed: 2.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 chair, 1 tv, 28.0ms\n",
      "Speed: 2.0ms pre-process, 28.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.3ms\n",
      "Speed: 1.0ms pre-process, 26.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.1ms\n",
      "Speed: 1.0ms pre-process, 26.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bench, 1 chair, 1 tv, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 23.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 25.0ms\n",
      "Speed: 2.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bench, 1 chair, 1 tv, 25.2ms\n",
      "Speed: 1.0ms pre-process, 25.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 26.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 23.0ms\n",
      "Speed: 0.0ms pre-process, 23.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 0.9ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 1 cell phone, 22.0ms\n",
      "Speed: 1.0ms pre-process, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 1 cell phone, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([2, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 cup, 1 chair, 1 tv, 1 cell phone, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 1 tv, 1 cell phone, 24.0ms\n",
      "Speed: 0.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 2 chairs, 1 tv, 1 cell phone, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 1 cell phone, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 1 chair, 1 tv, 1 cell phone, 35.1ms\n",
      "Speed: 2.0ms pre-process, 35.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 1 cell phone, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 1 cell phone, 28.0ms\n",
      "Speed: 1.0ms pre-process, 28.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 1 chair, 1 tv, 1 cell phone, 26.5ms\n",
      "Speed: 1.0ms pre-process, 26.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 2 chairs, 1 tv, 1 cell phone, 24.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 1 chair, 1 tv, 1 cell phone, 24.0ms\n",
      "Speed: 2.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 cup, 1 chair, 1 tv, 1 cell phone, 23.1ms\n",
      "Speed: 1.0ms pre-process, 23.1ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 bottle, 2 chairs, 1 tv, 1 cell phone, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 1 cell phone, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 1 cell phone, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 1 tv, 1 cell phone, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 1 tv, 1 cell phone, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 2 chairs, 1 tv, 1 cell phone, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 2 bottles, 1 chair, 1 tv, 1 cell phone, 30.0ms\n",
      "Speed: 1.0ms pre-process, 30.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 1 cell phone, 24.0ms\n",
      "Speed: 2.0ms pre-process, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 chair, 1 tv, 1 cell phone, 25.0ms\n",
      "Speed: 2.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 1 tv, 1 cell phone, 23.0ms\n",
      "Speed: 1.0ms pre-process, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 1 cell phone, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 tv, 1 cell phone, 25.2ms\n",
      "Speed: 1.0ms pre-process, 25.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 1 tv, 1 cell phone, 25.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([3, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 1 cell phone, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cup, 1 chair, 1 cell phone, 25.0ms\n",
      "Speed: 1.4ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 1 chair, 1 cell phone, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 chairs, 1 cell phone, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 cell phone, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 1 chair, 1 cell phone, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 cell phone, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 cell phone, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 1 bottle, 1 cell phone, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bottle, 1 cup, 1 chair, 1 cell phone, 24.0ms\n",
      "Speed: 1.0ms pre-process, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cup, 1 chair, 1 cell phone, 25.0ms\n",
      "Speed: 1.0ms pre-process, 25.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([4, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 3 persons, 1 cup, 1 chair, 1 cell phone, 26.0ms\n",
      "Speed: 0.0ms pre-process, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 1 cup, 1 chair, 26.0ms\n",
      "Speed: 1.0ms pre-process, 26.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n",
      "(480, 640, 3)\n",
      "torch.Size([6, 6])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = vid.read()\n",
    "    image = np.asarray(frame)\n",
    "    results = model.predict(image)\n",
    "    image = plot_bboxes(image, results[0].boxes.boxes, score=True, conf=0.6)\n",
    "    print(image.shape)\n",
    "    print(results[0].boxes.boxes.shape)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow(\"image\", image)  # if used in Python\n",
    "    # save image\n",
    "    cv2.imwrite(\"image.jpg\", image)\n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# # After the loop release the cap object\n",
    "# vid.release()\n",
    "# # Destroy all the windows\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[158, 186, 121],\n",
       "        [158, 186, 121],\n",
       "        [157, 185, 120],\n",
       "        ...,\n",
       "        [241, 235, 222],\n",
       "        [241, 234, 221],\n",
       "        [241, 234, 221]],\n",
       "\n",
       "       [[158, 186, 121],\n",
       "        [158, 186, 121],\n",
       "        [157, 185, 120],\n",
       "        ...,\n",
       "        [241, 235, 222],\n",
       "        [241, 234, 221],\n",
       "        [241, 234, 221]],\n",
       "\n",
       "       [[157, 185, 120],\n",
       "        [157, 185, 120],\n",
       "        [156, 184, 119],\n",
       "        ...,\n",
       "        [241, 234, 220],\n",
       "        [240, 233, 219],\n",
       "        [240, 233, 219]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[185, 185, 171],\n",
       "        [185, 185, 171],\n",
       "        [185, 184, 171],\n",
       "        ...,\n",
       "        [176, 184, 175],\n",
       "        [177, 185, 176],\n",
       "        [177, 185, 176]],\n",
       "\n",
       "       [[181, 181, 169],\n",
       "        [181, 181, 169],\n",
       "        [180, 180, 168],\n",
       "        ...,\n",
       "        [176, 184, 176],\n",
       "        [177, 185, 177],\n",
       "        [177, 185, 177]],\n",
       "\n",
       "       [[181, 181, 169],\n",
       "        [181, 181, 169],\n",
       "        [180, 180, 168],\n",
       "        ...,\n",
       "        [176, 184, 176],\n",
       "        [177, 185, 177],\n",
       "        [177, 185, 177]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_bboxes(image, results[0].boxes.boxes, score=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39739dead8b6e157ed7676b80302e88909c39a480c510e352b9abc4b517711ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
